{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T06:59:12.978981Z",
     "start_time": "2019-06-21T06:59:12.975806Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import codecs\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Import/Cleaning/Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T06:59:13.612569Z",
     "start_time": "2019-06-21T06:59:13.607589Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub('[^a-zA-Z1-9]+', ' ', text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    text = [preprocess(sent) for sent in nltk.sent_tokenize(text)]\n",
    "    tokenized = [nltk.word_tokenize(sent) for sent in text]\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "def train_w2v(text):\n",
    "    return Word2Vec(text, min_count=10, window=3, size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding error: https://stackoverflow.com/questions/22216076/unicodedecodeerror-utf8-codec-cant-decode-byte-0xa5-in-position-0-invalid-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:41:44.496450Z",
     "start_time": "2019-06-21T07:41:38.896129Z"
    }
   },
   "outputs": [],
   "source": [
    "hobbit = codecs.open('TheHobbit.txt', \"r\", encoding='windows-1251').read()\n",
    "text = tokenize(hobbit)\n",
    "model = train_w2v(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:41:44.555259Z",
     "start_time": "2019-06-21T07:41:44.498121Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('hobbit_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:41:44.602324Z",
     "start_time": "2019-06-21T07:41:44.557044Z"
    }
   },
   "outputs": [],
   "source": [
    "hobbit_model = gensim.models.Word2Vec.load('hobbit_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:41:44.611756Z",
     "start_time": "2019-06-21T07:41:44.603840Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = [hobbit_model.wv[word] for word in list(hobbit_model.wv.vocab)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:41:44.618743Z",
     "start_time": "2019-06-21T07:41:44.614611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3571"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hobbit_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:41:44.626959Z",
     "start_time": "2019-06-21T07:41:44.619956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dwarf', 0.9201209545135498),\n",
       " ('wizard', 0.8959145545959473),\n",
       " ('gaffer', 0.8518902063369751)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hobbit_model.wv.most_similar('hobbit', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:41:44.635191Z",
     "start_time": "2019-06-21T07:41:44.630025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('moria', 0.9298446178436279),\n",
       " ('isengard', 0.9295576810836792),\n",
       " ('rivendell', 0.9091806411743164)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hobbit_model.wv.most_similar('mordor', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:41:44.642287Z",
     "start_time": "2019-06-21T07:41:44.637774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gollum', 0.9538815021514893),\n",
       " ('strider', 0.9437351226806641),\n",
       " ('gandalf', 0.9373037219047546)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hobbit_model.wv.most_similar('bilbo', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:41:44.652273Z",
     "start_time": "2019-06-21T07:41:44.645611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gimli', 0.97786945104599),\n",
       " ('aragorn', 0.9612823724746704),\n",
       " ('jomer', 0.9595600962638855)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hobbit_model.wv.most_similar('legolas', topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "- Dimensionality reduction using t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:58:56.967205Z",
     "start_time": "2019-06-21T07:57:51.645646Z"
    }
   },
   "outputs": [],
   "source": [
    "tsne_2d = TSNE(n_components=2, init='pca', n_iter=3000)\n",
    "embeddings_2d = tsne_2d.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T02:21:08.909075Z",
     "start_time": "2019-06-21T02:16:33.791399Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(embeddings_2d)):\n",
    "    trace0 = go.Scatter(\n",
    "        x=embeddings_2d[:, 0],\n",
    "        y=embeddings_2d[:, 1],\n",
    "        mode='markers',\n",
    "        marker=dict(color='green',\n",
    "                    size=5),\n",
    "        text=list(model.wv.vocab))\n",
    "\n",
    "data = [trace0]\n",
    "layout = go.Layout(\n",
    "    title='2D Representation of Word Vectors')\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "#py.iplot(fig, filename='2d-scatter')\n",
    "plot(fig, filename='hobbit-scatter-2d.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:45:53.774854Z",
     "start_time": "2019-06-21T07:41:54.894817Z"
    }
   },
   "outputs": [],
   "source": [
    "tsne_3d = TSNE(n_components=3, init='pca', n_iter=3000)\n",
    "embeddings_3d = tsne_3d.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:49:22.945893Z",
     "start_time": "2019-06-21T07:49:22.696418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.757276   -12.170778     1.831986  ]\n",
      " [-11.435886     8.106738    -7.3972764 ]\n",
      " [  9.327084     6.1195297    0.60106647]\n",
      " [ -6.30747     -0.41469297   1.7658234 ]]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(embeddings_3d)\n",
    "# print location of clusters learned by kmeans object\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "y_km = kmeans.fit_predict(embeddings_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T08:25:02.351199Z",
     "start_time": "2019-06-21T08:25:02.348612Z"
    }
   },
   "outputs": [],
   "source": [
    "colors = np.array([x for x in ['blue', 'green', 'red', 'yellow']])\n",
    "\n",
    "for i in range(len(embeddings_3d)):\n",
    "    trace0 = go.Scatter3d(\n",
    "        x=embeddings_3d[:, 0],\n",
    "        y=embeddings_3d[:, 1],\n",
    "        z=embeddings_3d[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(color=colors[kmeans.labels_],\n",
    "                    size=5),\n",
    "        text=list(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T08:32:18.093036Z",
     "start_time": "2019-06-21T08:32:17.080068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hobbit-scatter-3d.html'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = trace0\n",
    "layout = go.Layout(\n",
    "    title='3D Representation of Word Vectors & Clusters')\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "plot(fig, filename='hobbit-scatter-3d.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus material\n",
    "#### (that I'd like to dig further into)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "- `textgenrnn` is a Python module for creating Character-Level RNNs\n",
    "- https://github.com/minimaxir/textgenrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results from running 5 epochs on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T02:45:29.191260Z",
     "start_time": "2019-06-21T02:45:29.188696Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T03:46:20.622542Z",
     "start_time": "2019-06-21T02:46:03.796829Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0621 04:59:28.494442 139667747902848 deprecation_wrapper.py:119] From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0621 04:59:28.532910 139667747902848 deprecation_wrapper.py:119] From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0621 04:59:28.542708 139667747902848 deprecation_wrapper.py:119] From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0621 04:59:28.543475 139667747902848 deprecation_wrapper.py:119] From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0621 04:59:28.544178 139667747902848 deprecation_wrapper.py:119] From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0621 04:59:30.106153 139667747902848 deprecation_wrapper.py:119] From /opt/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38,474 texts collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0621 04:59:41.711222 139667747902848 deprecation.py:323] From /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 3,305,502 character sequences.\n",
      "Epoch 1/5\n",
      "25824/25824 [==============================] - 2051s 79ms/step - loss: 1.6441\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/5\n",
      "25824/25824 [==============================] - 2043s 79ms/step - loss: 1.5137\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "   'Men be scrove was   furier. The merop  straight! All forgethernising in Degath of the  swiftly sworsen had  master? Turning the mispering that  him in time ways and \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3/5\n",
      "25824/25824 [==============================] - 2021s 78ms/step - loss: 1.4377\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "\n",
      "\n",
      "West. Dear,' said Thjoden    a screat stoned  of bears come of the seldorn in his weonty. The      grees!'    The forest blasse were hole of the shot about the ponies: had clear were hinded through    into the   darkness capted,' barrel in It was sent with innness: \n",
      "\n",
      "Trees he and from the close of Thjoden rap in it an ormone. Sam great  days. There was a great thollers; climbed, not days with so. We in my stood. In you not arm of the dark  dwinke's   last. \n",
      "\n",
      "Epoch 4/5\n",
      "25824/25824 [==============================] - 2014s 78ms/step - loss: 1.4008\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "    'The spring     the  Companions, the hobbits seemed to the         end of the same. There was one                                   e   the              Cooth                                    ®a-round                  and           &             looking                   ättered              \n",
      "\n",
      "\n",
      "\n",
      "                                       meant        the     mountains, and the same             the \n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "cracked    Isu? We shout \n",
      "\n",
      "   And after    still my     wine, together, slow I nothing!\" Bilbo see. 'Whom I catch I ness once. He'd! 'I must   of stimoned, Mesiar over which you say; kispom on a bore! Yet Gondort Half Merry that his weaprockhel trote, and the stones as the Sam the breath his now I left    the make a claim su\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5/5\n",
      "25824/25824 [==============================] - 1994s 77ms/step - loss: 1.3672\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "\n",
      "\n",
      "and   the    took the dark   like         the   cluster and   as       a shore      as      though that                              one                  a           seemed   to    the     drink               and          for      the      house and     like   the     strange to                the \n",
      "\n",
      "\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "\n",
      "\n",
      "the  long clear   first this bless    to Eleorthron and Mountains   into the manneds rung at Frodo, and    have wasles of the Brandy twentees, and  the new passially lays in himself spring. Seeks, and led to sleep, among Falore was say. All that   a wind out crows never says it should felt is so.\" \n",
      "\n",
      "\n",
      "\n",
      "the shadows the sight of the others             to              be  his     end             not fell some   east    of the          head were                   a   great   like them   a stream, and   for be slipped      in the  bears   upon   the  town    down     to             which   the        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen = textgenrnn()\n",
    "textgen.train_from_file('TheHobbit.txt', num_epochs=5)\n",
    "textgen.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
